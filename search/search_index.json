{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#devops-for-data-scientists","title":"DevOps for data scientists","text":"<p>Webpage: https://skaftenicki.github.io/ku_devops/.</p> <p>This repository contains a small introduction to developer operations (DevOps) for students in the course Grundl\u00e6ggende Data Science (GDS) at Copenhagen University. The four core topics covered are:</p> <ul> <li>Virtual environments</li> <li>Version control</li> <li>Experiment tracking</li> <li>Code testing</li> </ul> <p>You are supposed to do them in the order listed. When doing the exercises, to maximize your DevOps experience you  should prioritize:</p> <ol> <li> <p>Make yourself familiar with running commands in the terminal. The terminal can be a scary place, but it is an    essential skill to be able to run commands without relying on a graphical interface. If you want a good introduction     to using the shell, I highly recommend the first two lectures from this MIT course.</p> </li> <li> <p>Only use scripts e.g. no notebooks for these exercises. Notebooks have their benefits but the fact is that developing    software in the real world is done in scripts. Therefore make sure that whenever you are writing code for the    exercises do this in <code>.py</code> scripts. If you feel like you miss the interactiveness of notebooks when working with the     script I can highly recommend giving ipython a spin.</p> </li> <li> <p>Get a good code editor, and try using it. If you do not have one, I can highly recommend    Visual Studio Code that are a lightweight editor, but through extensions can become     powerful. Otherwise, I also recommend PyCharm.</p> </li> </ol> <p>Why should a data scientist care about DevOps? Because DevOps provides processes and tools for creating reproducible experiments at scale when working with any kind of computer science/data science. Being able to ensure that your  experiments are reproducible is important in the context of the scientific method:</p> <p>  Image credit  </p> <p>Without reproducibility, the method breaks at the experimental stage, as non-reproducible experiments will most likely lead to different results and thereby different conclusions on the initial hypothesis.</p> <p>For a much more complete set of material on this topic, see this course which goes over the nearly complete pipeline of designing, modeling and deploying machine learning applications.</p>"},{"location":"code_testing/","title":"Code Testing","text":""},{"location":"code_testing/#code-testing","title":"Code testing","text":"<p>Code testing is an essential part of what we call continuous integration (CI) within DevOps. Continuous X assumes that we have a (long) developer pipeline (see image below) where we want to make some changes to our code e.g:</p> <ul> <li>Update our training data or data processing</li> <li>Update our model architecture</li> <li>Something else ...</li> </ul> <p>Any code change we will expect will influence the final result. The problem with doing changes to the start of our  pipeline is that we want the change to propagate all the way through to the end of the pipeline.</p> <p>  Image credit  </p> <p>This is where continuous integration comes into play. The word continuous here refers to the fact that the pipeline should continuously be updated as we make code changes. You can also choose to think of this as the automatization  of processes. As indicated in the image above, CI usually takes care of the first part of the developer pipeline which  has to do with the code base, code building and code testing.</p> <p>In the middle of the figure, we have the word test, which refers to testing our code. Testing are checks that we implement that we can run after we have made changes to our code to make sure that it is still doing what we think it should do, and that the changes we have made have not introduced bugs.</p> <p>The kind of tests we are going to look at are called unit testing. Unit  testing refers to the practice of writing test that tests individual parts of your code base to test for correctness. By  unit, you can therefore think of a function, module or in general any object. By writing tests in this way it should be very easy to isolate which part of the code broke after an update to the code base. Another way to test your code base would be through integration testing which is equally important but we are not going to focus on it in this course.</p>"},{"location":"code_testing/#exercises","title":"Exercises","text":"<ol> <li> <p>Read the getting started guide for pytest which is the     testing framework that we are going to use. We have started a file for you called <code>test_numpy.py</code> which you can     implement the remaning of the exercises in.</p> </li> <li> <p>Install pytest:</p> <pre><code>pip install pytest\n</code></pre> </li> <li> <p>Write some tests. We are going to check the properties of some <code>numpy</code> functions for the sake of this exercise,      however, normally you would write a test for your code and not third-party packages. Below are some guidelines on     some tests that should be implemented, but you are of course free to implement more tests. You can at any point check     if your tests are passing by typing in a terminal</p> <pre><code>pytest tests/\n</code></pre> <p>When you implement a test you need to follow two standards, for <code>pytest</code> to be able to find your tests. First, any  files created (except <code>__init__.py</code>) should always start with <code>test_*.py</code>. Secondly, any test implemented needs to  be wrapped into its function that again needs to start with <code>test_</code>:</p> <pre><code># this will be found and executed by pytest\ndef test_something():\n    ...\n\n# this will not be found and executed by pytest\ndef something_to_test():\n    ...\n</code></pre> <ol> <li> <p>Start by testing <code>np.sin</code>. Add a <code>test_np_sin</code> function to the <code>test_numpy.py</code> where you check that the function     correctly works for three different values.</p> </li> <li> <p>Afterward, let's test <code>np.linalg.eig</code> which calculates the eigen decomposition for a given matrix. You should      test the following:</p> <ul> <li>For a given <code>(N,N)</code> matrix, the shapes of the eigenvector matrix and eigenvalue matrix is also <code>(N,N)</code></li> <li>For a randomly generated symmetric matrix, all the eigenvalues are real</li> <li>For a positive semidefinite matrix, all the eigenvalues are real and non-negative</li> </ul> </li> <li> <p>Good code raises errors and gives out warnings in appropriate places. This is often in the case of some invalid     combination of input to your script. Let's take a look at <code>np.arange</code> which one could argue should be better at     raising errors. Try to think about what the following line should return and afterward try to execute it:</p> <pre><code>np.arange(start=0, stop=5, step=0.5, dtype=np.int32)\n</code></pre> <p>I would argue that the output does not make sense, because the input does not make sense. Let's fix that:</p> <pre><code>def new_arange(start, stop, step, dtype):\n    if isinstance(step, float) and dtype == np.int32:\n        raise ValueError('`step` argument cannot be float at the same time as argument `dtype` being int')\n    return np.arange(start=start, stop=stop, step=step, dtype=dtype)\n</code></pre> <p>Try implementing a test that checks that the error is correctly raised if the input is wrong. It should look a bit like this</p> <p><code>python def test_valueerror_being_raised():     with pytest.raises(ValueError, match='this is the message printed')         new_arange(start=0, stop=5, step=0.5, dtype=np.int32)</code></p> </li> <li> <p>A test is only as good as the error message it gives, and by default <code>assert</code> will only report that the check     failed. However, we can help our self and others by adding strings after <code>assert</code> like</p> <pre><code>assert len(train_dataset) == N_train, \"Dataset did not have the correct number of samples\"\n</code></pre> <p>Add such comments to the assert statements you just did in privious exercises.</p> </li> </ol> </li> <li> <p>After writing the different tests, make sure that they are passing locally.</p> </li> <li> <p>We often want to check a function/module for various input arguments. In this case, you could write the same test      over and over again for the different input, but <code>pytest</code> also has build in support for this with the use of the     pytest.mark.parametrize decorator.     Implement a parametrized test and make sure that it runs for different inputs.</p> </li> <li> <p>(Optional) There is no way of measuring how good the test you have written is. However, what we can measure is the     code coverage. Code coverage refers to the percentage of your codebase that gets run when all your tests are      executed. Having a high coverage at least means that all your code will run when executed.</p> <ol> <li> <p>Install coverage</p> <pre><code>pip install coverage\n</code></pre> </li> <li> <p>Instead of running your tests directly with <code>pytest</code>, now do</p> <pre><code>coverage run -m pytest tests/\n</code></pre> </li> <li> <p>To get a simple coverage report simply type</p> <pre><code>coverage report\n</code></pre> <p>which will give you the percentage of cover in each of your files. You can also write</p> <pre><code>coverage report -m\n</code></pre> <p>to get the exact lines that were missed by your tests.</p> </li> </ol> </li> </ol> <p>That covers the basics of writing unittest for Python code. We want to note that <code>pytest</code> of course is not the only framework for doing this. Python actually has a build in framework called unittest for doing this also (but <code>pytest</code> offers a bit more features). Another open-source framework that you could choose to checkout is hypothesis which can really help catch errors in corner cases of your code. In addition to writing unittests it is also highly recommended to test code that you include in your docstring belonging to your functions and modulus to make sure that any code there is in your documentation is also correct. For such testing, we can highly recommend using pythons build-in framework doctest.</p>"},{"location":"experiment_tracking/","title":"Experiment Tracking","text":""},{"location":"experiment_tracking/#experiment-tracking","title":"Experiment tracking","text":"<p>Experiment logging or model monitoring is an important part of understanding what is going on with your model. It can help you debug your model and tweak your models to perfection.</p> <p>The most basic logging we can do is write the metric that our model is producing to the terminal or a file for later inspection. We can then also use tools such as matplotlib for plotting our data, model fit, etc. This kind of workflow may be enough when doing smaller experiments or working alone on a project, but there is no way around using a proper experiment tracker and visualizer when doing large-scale experiments in collaboration with others. It especially becomes important when you want to compare performance between different runs.</p> <p>There exist many tools for logging your experiments, with some of them being:</p> <ul> <li>Tensorboard</li> <li>Comet</li> <li>MLFlow</li> <li>Neptune</li> <li>Weights and Bias</li> </ul> <p>All of the frameworks offer many of the same functionalities. We are going to use Weights and Bias (wandb), as it  supports everything we need in this course. Additionally, it is an excellent tool for collaboration and sharing of results.</p>"},{"location":"experiment_tracking/#exercises","title":"Exercises","text":"<ol> <li> <p>Start by creating an account at wandb. I recommend using your Github account but feel     free to choose what you want. When you are logged in you should get an API key of length 40. Copy this for later     use (HINT: if you forgot to copy the API key, you can find it under settings).</p> </li> <li> <p>Next, install wandb on your laptop</p> <pre><code>pip install wandb\n</code></pre> </li> <li> <p>Now connect to your wandb account</p> <pre><code>wandb login\n</code></pre> <p>you will be asked to provide the 40-length API key. The connection should remain open to the wandb server even when you close the terminal, such that you do not have to log in each time. If using <code>wandb</code> in a notebook you need to manually close the connection using <code>wandb.finish()</code>.</p> </li> <li> <p>With the setup done, we are now ready to incorporate <code>wandb</code> into our code. The interface is fairly simple, and     the docs are fairly well written to get you through the exercises (HINT: the two methods     you need to call are <code>wandb.init</code> and <code>wandb.log</code>).</p> <ol> <li> <p>We have provided a sample script called <code>wandb_script.py</code> that again implements a small classification model     on the iris-dataset. Add <code>wandb.init</code> and <code>wandb.log</code> in the appropriate places such that wandb is initialized     correctly and such that both accuracy, f1, negative log likelihood get logged.</p> </li> <li> <p>When you are done, try running the script:</p> <pre><code>python wandb_script.py\n</code></pre> <p>In particular look at the output that gets written.</p> </li> <li> <p>Next, go to the webpage and lookup the project you created and logged something to. You should hopefully see one     experiment logged, which is not that interesting at the moment. However, we can checkout one important feature      if you go to the Overview tab for a specific experiment, like the image below:</p> <p><p> </p></p> <p>As you hopefully can see, we get the exact Python version, git commit, command used etc. to run the experiment, which should make it completely reproducible!</p> </li> </ol> </li> <li> <p>The <code>wandb_script.py</code> already supports using different models by passing them in as an argument when running the      script</p> <pre><code>python wandb_script.py --model LogisticRegression\n</code></pre> <p>try running the script with all the different models. However, before doing so it is a good idea to also log the model we are using to wandb. Fill out the <code>config</code> arg in <code>wandb.init</code> with the model hyperparameter and run all combinations.</p> </li> <li> <p>If you managed to do the last part, you should hopefully have logged multiple experiments now. Look at your project     page again in your web browser. You should see all your experiments. In particular check out the <code>Table</code> tab (as in     the image below) which can give a nice condensed overview of your experiments.</p> <p><p> </p></p> </li> <li> <p>Wandb can log a lot more than just scalar values. This could be an image (numpy array), a histogram or a matplotlib     figure. In all cases, the logging is still going to use <code>wandb.log</code> but you need extra calls to <code>wandb.Image</code> etc.     depending on what you choose to log. Add the following code to the <code>wandb_script.py</code> at the end and afterward figure      out how to call <code>wandb.log</code> to log the figure:</p> <pre><code>import seaborn as sns\n# Plot also the training points\nfig = sns.scatterplot(\n    x=X[:, 0],\n    y=X[:, 1],\n    hue=df.target_names[y],\n    alpha=1.0,\n    edgecolor=\"black\",\n)\n</code></pre> </li> <li> <p>Wandb has a nice integration with scikit-learn which can be very useful, so let's integrate that into our script     for help look at this guide and this     notebook     . Add the following code at the end of the script:</p> <pre><code>model = models[args.model]\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_probas = model.predict_proba(X_test)\n</code></pre> <p>and then try to include the following lines of code:</p> <pre><code>wandb.sklearn.plot_class_proportions(y_train, y_test, labels)\nwandb.sklearn.plot_learning_curve(model, X_train, y_train)\nwandb.sklearn.plot_roc(y_test, y_probas, labels)\nwandb.sklearn.plot_precision_recall(y_test, y_probas, labels)\nwandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels)\n</code></pre> <p>and run the script again (using whatever model you like). You may not understand what each command plots, but hopefully, this will be more clear later on. The important part is that you can see how a lot of information can be logged about a single experiment.</p> </li> <li> <p>When calling <code>wandb.init</code> you have two arguments called <code>project</code> and <code>entity</code>. Make sure that you understand these     and try them out. It will come in handy for your group work as they essentially allow multiple users to upload their     own runs to the same project in <code>wandb</code>.</p> </li> <li> <p>Another awesome feature of wandb is doing hyperparameter sweeps e.g. finding the best parameters for a     given model. You can do this in scikit-learn, however, the core advantage of using wandb is that the hyperparameter     optimization gets abstracted away, meaning that if you want to do hyperparameter sweeping for a framework other than     scikit-learn it would still be the same code. We provide a sample script <code>wandb_sweep.py</code> that does hyperparameter     optimization for you. Try to go over it and try to make sense of what is going on. Afterward, execute it</p> <pre><code>python wandb_sweep.py\n</code></pre> <p>It will take some time to run (by default it runs 10 combinations of parameters). Afterwards, checkout the sweep tab on the website, where you should figure out:</p> <ul> <li>What combination of parameters leads to the highest accuracy value?</li> <li>What parameter has the highest importance for getting a high accuracy value?</li> </ul> </li> </ol>"},{"location":"version_control/","title":"Version Control","text":""},{"location":"version_control/#version-control","title":"Version control","text":"<p>Proper collaboration with other people will require that you work on the same codebase in an organized manner. This is the reason that version control exists. Simply stated, it is a way to keep track of:</p> <ul> <li>Who made changes to the code</li> <li>When did the change happen</li> <li>What changes were made</li> </ul> <p>For a full explanation please see this page</p> <p>Secondly, it is important to note that GitHub is not git! GitHub is the dominating player when it comes to hosting repositories but that does not mean that they are the only one providing free repository hosting (see bitbucket or gitlab for some other examples).</p> <p>That said we will be using git and Github in these exercises.</p> <p>  Image credit  </p>"},{"location":"version_control/#initial-config","title":"Initial config","text":"<ol> <li> <p>Install git on your computer and make sure     that your installation is working by writing <code>git help</code> in a terminal and it should show you the help message     for git.</p> </li> <li> <p>Create a github account if you do not already have one.</p> </li> <li> <p>To make sure that we do not have to type in our GitHub username every time that we want to make some changes,     we can once and for all set them on our local machine</p> <pre><code># type in a terminal\ngit config --global user.email &lt;email&gt;\ngit config --global user.password &lt;password&gt;\ngit config --global credential.helper store\n</code></pre> <p>where you provide your email and password. The last line will make sure that you do not have to type in your password every time you want to push something to your repository.</p> </li> </ol>"},{"location":"version_control/#git-overview","title":"Git Overview","text":"<p>The most simple way to think of version control is that it is just nodes with lines connecting them</p> <p> </p> <p>Each node, which we call a commit is uniquely identified by a hash string. Each node stores what our code looked like  then (when we made the commit) and using the hash codes we can easily revert to a specific point in time.</p> <p>The commits are made up of local changes that we make to our code. A basic workflow for adding commits is seen below</p> <p> </p> <p>Assuming that we have made some changes to our local working directory and that we want to get these updates to be online in the remote repository we have to do the following steps:</p> <ul> <li> <p>First, we run the command <code>git add</code>. This will move our changes to the staging area. While changes are in the     staging area we can very easily revert them (using <code>git restore</code>). There has therefore not been assigned a unique     hash to the code yet, and we can therefore still overwrite it.</p> </li> <li> <p>To take our code from the staging area and make it into a commit, we simply run <code>git commit</code> which will locally     add a note to the graph. It is important again, that we have not pushed the commit to the online repository yet.</p> </li> <li> <p>Finally, we want others to be able to use the changes that we made. We do a simple <code>git push</code> and our     commit gets online</p> </li> </ul> <p>Of course, the real power of version control is the ability to make branches, as in the image below</p> <p>  Image credit  </p> <p>Each branch can contain code that is not present on other branches. This is useful when you are many developers working  together on the same project.</p>"},{"location":"version_control/#exercises","title":"Exercises","text":"<ol> <li> <p>In your GitHub account create a repository, where the intention is to upload and version control a script</p> <ol> <li> <p>After creating the repository, clone it to your computer</p> <pre><code>git clone https://github.com/&lt;my_user_name&gt;/&lt;my_repository_name&gt;.git\n</code></pre> </li> </ol> </li> <li> <p>Create/Copy/Move the <code>simple_classifier.py</code> file and the <code>requirements.txt</code> file from the last virtual environment         exercises into this repository.</p> </li> <li> <p>Add the files to a commit by using <code>git add</code> command</p> </li> <li> <p>Commit the files using <code>git commit</code></p> </li> <li> <p>Finally, push the files to your repository using <code>git push</code>. Make sure to check online that the files have been         updated in your repository.</p> </li> <li> <p>You can always use the command <code>git status</code> to check where you are in the process of making a commit.</p> </li> <li> <p>Make sure that you understand how to make branches, as this will allow you to try out code changes without     messing with your working code. Creating a new branch can be done using:</p> <pre><code># create a new branch\ngit checkout -b &lt;my_branch_name&gt;\n</code></pre> <p>Afterwards, you can use <code>git checkout</code> to change between branches (remember to commit your work!) Try adding something (a file, a new line of code etc.) to the newly created branch, commit it and try changing back to master afterward. You should hopefully see whatever you added on the branch is not present on the main branch.</p> </li> <li> <p>Try to make a couple of commits to either your newly created branch or your main branch, let's say at least two.     Afterwards, try executing</p> <pre><code>git log\n</code></pre> <p>which will give you info about the last couple of commits. Try to figure out how you can roll back to a previous commit? Hint: you need to use the <code>git checkout</code> command + the commit hash you get from <code>git log</code>.</p> </li> <li> <p>As a final exercise, we want to simulate a merge conflict, which happens when two users try to commit changes to      the same lines of code in the codebase, and git is not able to resolve how the different commits should      be integrated.</p> <ol> <li> <p>In your browser, open your repository, go to any file of your choosing and click the edit button (see image below     ) and make some changes to the file. For example, if you choose a Python file you can just import some random     packages at the top of the file. Commit the change.</p> <p><p> </p></p> </li> <li> <p>Make sure not to pull the change you just made to your local computer. Locally make changes to the same     file in the same lines and commit them afterward.</p> </li> </ol> </li> <li> <p>Now try to <code>git pull</code> the online changes. What should (hopefully) happen is that git will tell you that it found         a merge conflict that needs to be resolved. Open the file and you should see something like this</p> <pre><code>```txt\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nthis is some content to mess with\ncontent to append\n=======\ntotally different content to merge later\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; master\n```\n\nthis should be interpreted as everything that's between `&lt;&lt;&lt;&lt;&lt;&lt;&lt;` and `=======` are the changes made by your \nlocal commit and everything between `=======` and `&gt;&gt;&gt;&gt;&gt;&gt;&gt;` are the changes you are trying to pull. To fix the \nmerge conflict you simply have to make the code in the two \"cells\" work together. When you are done, remove the\nidentifiers `&lt;&lt;&lt;&lt;&lt;&lt;&lt;`, `=======` and `&gt;&gt;&gt;&gt;&gt;&gt;&gt;`.\n</code></pre> <ol> <li>Finally, commit the merge and try to push.</li> </ol> </li> </ol>"},{"location":"virtual_environments/","title":"Virtual Environment","text":""},{"location":"virtual_environments/#virtual-environments","title":"Virtual environments","text":"<p>Python is a great programming language and this is mostly due to its vast ecosystem of packages. No matter what you want to do, there is probably a package that can get you started. Just try to remember when the last time you wrote a program only using the Python standard library. Probably never. For this reason, we need a way to install third-party packages and this is where package managers come into play.</p> <p>You have probably already used <code>pip</code> for the longest time, which is the default package manager for Python. <code>pip</code> is great for beginners but it is missing one essential feature that you will need as a developer or data scientist: virtual environments. Virtual environments are an essential way to make sure that the dependencies of different projects do not cross-contaminate each other. As a naive example, consider project A requires <code>torch==1.3.0</code> and project B requires <code>torch==2.0</code>, then </p> <pre><code>cd project_A  # move to project A\npip install torch==1.3.0  # install old torch version\ncd ../project_B  # move to project B\npip install torch==2.0  # install new torch version\ncd ../project_A  # move back to project A\npython main.py  # try executing main script from project A\n</code></pre> <p>will mean that even though we are executing the main script from project A's folder, it will use <code>torch==2.0</code> instead of <code>torch==1.3.0</code> because that is the last version we installed because in both cases <code>pip</code> will install the package into the same environment, in this case, the global environment. Instead, if we did something like:</p> Unix/macOSWindows <pre><code>cd project_A  # move to project A\npython -m venv env  # create a virtual environment in project A\nsource env/bin/activate  # activate that virtual environment\npip install torch==1.3.0  # Install the old torch version into the virtual environment belonging to project A\ncd ../project_B  # move to project B\npython -m venv env  # create a virtual environment in project B\nsource env/bin/activate  # activate that virtual environment\npip install torch==2.0  # Install new torch version into the virtual environment belonging to project B\ncd ../project_A  # Move back to project A\nsource env/bin/activate  # Activate the virtual environment belonging to project A\npython main.py  # Succeed in executing the main script from project A\n</code></pre> <pre><code>cd project_A  # Move to project A\npython -m venv env  # Create a virtual environment in project A\n.\\env\\Scripts\\activate  # Activate that virtual environment\npip install torch==1.3.0  # Install the old torch version into the virtual environment belonging to project A\ncd ../project_B  # Move to project B\npython -m venv env  # Create a virtual environment in project B\n.\\env\\Scripts\\activate  # Activate that virtual environment\npip install torch==2.0  # Install new torch version into the virtual environment belonging to project B\ncd ../project_A  # Move back to project A\n.\\env\\Scripts\\activate  # Activate the virtual environment belonging to project A\npython main.py  # Succeed in executing the main script from project A\n</code></pre> <p>then we would be sure that <code>torch==1.3.0</code> is used when executing <code>main.py</code> in project A because we are using two different virtual environments. In the above case, we used the venv module which is the built-in Python module for creating virtual environments. <code>venv+pip</code> is arguably a good combination but when working on multiple projects it can quickly become a hassle to manage all the different virtual environments yourself, remembering which Python version to use, which packages to install and so on.</p> <p>For this reason, several package managers have been created that can help you manage your virtual environments and dependencies, with some of the most popular being:</p> <ul> <li>conda</li> <li>pipenv</li> <li>poetry</li> <li>pipx</li> <li>hatch</li> <li>pdm</li> </ul> <p>In these exercises, we are going to be looking at how we can use <code>conda</code> to control dependencies when we are working on python projects. Many of you may already have <code>conda</code> installed, but most people have never actually used it. The  workflow presented in these exercises for managing dependencies are as follows</p> <ul> <li>Use <code>conda</code> to create environments</li> <li>Use <code>pip</code> to install packages in that environment</li> </ul> <p>It is most likely not the optimal way of doing things but where conda shines over other dependency managers is that it  supports all three major operating systems (Windows, OS, Linux) the best. Therefore, it is a great tool for teaching about virtual environments. Additionally, many local compute clusters in universities only allow you to work on the cluster if you use virtual environments through conda.</p>"},{"location":"virtual_environments/#exercises","title":"Exercises","text":"<ol> <li> <p>Download and install <code>conda</code>. You are free to either install full <code>conda</code> or the much simpler version <code>miniconda</code>.     The core difference between the two packages is that <code>conda</code> already comes with a lot of packages that you would     normally have to install with <code>miniconda</code>. The downside is that <code>conda</code> is a much larger package which can be a     huge disadvantage on smaller devices.</p> </li> <li> <p>Start a terminal or command prompt and type in <code>conda help</code> which should show you the help page for the different     commands that you can use with conda. If this does not work you probably need to set some system variable to     point to the conda installation</p> </li> <li> <p>The first important <code>conda</code> command is <code>create</code> which will create a new environment</p> <pre><code>conda create -n \"my_environment\" python=3.11\n</code></pre> <p>Execute the command. What does the <code>-n</code> flag do? What does the <code>python=3.11</code> flag do?</p> <p>Solution!  The <code>-n</code> flag is used to specify the name of the environment and the <code>python=3.11</code> flag is used to specify the  version of python that should be installed in the environment. In general, you can call <code>conda create --help</code> to get information about the different flags you can use with the <code>create</code> command. </p> </li> <li> <p>Afterward, use the <code>conda activate</code> command to activate the environment.</p> </li> <li> <p>After entering the environment, what <code>pip</code> command should you execute to get a list of all the dependencies already     installed in the environment?</p> <p>Solution! <code>pip freeze</code> </p> </li> <li> <p>We are now ready to install some dependencies. Try to get the script <code>simple_classifier.py</code> running. Essentially,     you need to iteratively call</p> <pre><code>python simple_classifier.py\n</code></pre> <p>and</p> <pre><code>pip install &lt;missing-package&gt;\n</code></pre> <p>Until the script runs.</p> </li> <li> <p>The way we usually communicate to other people the requirements needed to run our Python applications/scripts are     called <code>requirement.txt</code> files. These files are a simple list of dependencies with the format</p> <pre><code>dependency1==X.Y.Z\ndependency2==X.Y.Z\n</code></pre> <p>Where X.Y.Z is the particular version of that package. Construct a <code>requirements.txt</code> file containing the dependencies you just installed to run the script. Remember to specify the exact version you have used!</p> </li> <li> <p>We are often interested in listing only the bare minimum necessary to run our code in the <code>requirements.txt</code> file.     If you have written more than 2 dependencies in the last exercise, you have too many. Try figuring out what     two are strictly necessary to get the application running?</p> </li> <li> <p>When you think you have managed to create the file, let's try to test that it works. Execute these four commands:</p> <pre><code>conda create -y -n \"newenv\" python=3.11\nconda activate newenv\npip install -r requirements.txt\npython simple_classifier.py\n</code></pre> <p>Make sure you understand what the four commands does. If it completes without errors, congratulations on creating  your first reproducible virtual environment.</p> </li> <li> <p>Hopefully, you will be using multiple environments in the future and forget from time to time what you call them.     Which <code>conda</code> commando gives you a list of all the environments that you have created? Hint: look at this     conda cheat sheet</p> <p>Solution! <code>conda env list</code> </p> </li> <li> <p>Finally, make sure you also know how to delete unused environments as these can fill up your laptop. Figure out the     command to remove the <code>newenv</code> environment created in the previous exercise.</p> <p>Solution! <code>conda env remove -n newenv</code> </p> </li> </ol>"}]}